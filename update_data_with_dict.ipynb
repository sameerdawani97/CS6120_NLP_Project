{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164570dd-d5e5-41a1-a7be-04d459460ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/armanenginsucu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Download the 'wordnet' dataset from NLTK, which is useful for finding word synonyms\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa0dd8a-ffbf-478e-a0b3-76b8567e9492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics Data:\n",
      "            artist_all          artist_base  rank                       song  \\\n",
      "0          percy faith          percy faith     1  theme from a summer place   \n",
      "1           jim reeves           jim reeves     2           he'll have to go   \n",
      "2  the everly brothers  the everly brothers     3              cathy's clown   \n",
      "3       johnny preston       johnny preston     4               running bear   \n",
      "4         mark dinning         mark dinning     5                 teen angel   \n",
      "\n",
      "   year artist_featured                 song_clean         artist_clean  \\\n",
      "0  1960             NaN  theme from a summer place          percy faith   \n",
      "1  1960             NaN            hell have to go           jim reeves   \n",
      "2  1960             NaN               cathys clown  the everly brothers   \n",
      "3  1960             NaN               running bear       johnny preston   \n",
      "4  1960             NaN                 teen angel         mark dinning   \n",
      "\n",
      "                                              lyrics  acousticness  ...  \\\n",
      "0  theres a summer place where it may rain or sto...         0.631  ...   \n",
      "1  put your sweet lips a little closer to the pho...         0.909  ...   \n",
      "2   dont want your love any more dont want your k...         0.412  ...   \n",
      "3  on the bank of the river stood running bear yo...         0.854  ...   \n",
      "4  teen angel teen angel teen angel that fateful ...         0.936  ...   \n",
      "\n",
      "   speechiness    tempo  time_signature  valence  duration_min  num_words  \\\n",
      "0       0.0253   92.631             4.0    0.749      2.414883      104.0   \n",
      "1       0.0379   81.181             3.0    0.200      2.310667      152.0   \n",
      "2       0.0339  119.809             4.0    0.866      2.400217      121.0   \n",
      "3       0.0530  119.987             4.0    0.822      2.636667      220.0   \n",
      "4       0.0459  101.517             4.0    0.282      2.664883      109.0   \n",
      "\n",
      "   words_per_sec  num_uniq_words  decade uniq_ratio  \n",
      "0       0.717771            58.0    1960   1.793103  \n",
      "1       1.096365            69.0    1960   2.202899  \n",
      "2       0.840202            64.0    1960   1.890625  \n",
      "3       1.390645            89.0    1960   2.471910  \n",
      "4       0.681706            73.0    1960   1.493151  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Profanity Data:\n",
      "        text canonical_form_1 canonical_form_2 canonical_form_3  \\\n",
      "0         69               69              NaN              NaN   \n",
      "1        @55              ass              NaN              NaN   \n",
      "2   @ssfcker             fuck              ass              NaN   \n",
      "3  @ssfucker             fuck              ass              NaN   \n",
      "4  @ssfvcker             fuck              ass              NaN   \n",
      "\n",
      "                     category_1                   category_2 category_3  \\\n",
      "0  sexual anatomy / sexual acts                          NaN        NaN   \n",
      "1  sexual anatomy / sexual acts                          NaN        NaN   \n",
      "2  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
      "3  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
      "4  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
      "\n",
      "   severity_rating severity_description  \n",
      "0              1.0                 Mild  \n",
      "1              1.0                 Mild  \n",
      "2              2.8               Severe  \n",
      "3              2.8               Severe  \n",
      "4              2.4               Strong  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the data from the CSV files into DataFrames\n",
    "lyrics_df = pd.read_csv('billboard-lyrics-spotify.csv')\n",
    "profanity_df = pd.read_csv('profanity_en.csv')\n",
    "\n",
    "# Display a quick preview of the first few rows in both datasets to get a sense of the data\n",
    "print(\"Lyrics Data:\")\n",
    "print(lyrics_df.head())\n",
    "\n",
    "print(\"\\nProfanity Data:\")\n",
    "print(profanity_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c055e8c-2cf4-41b2-b467-024fefdcd8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create dictionaries for sexual, racial, and religious content from 'profanity_en.csv'\n",
    "def build_dictionaries(profanity_df):\n",
    "    sexual_content_dict = set()\n",
    "    racial_content_dict = set()\n",
    "    religious_content_dict = set()\n",
    "\n",
    "    # loop through the rows and handle cases where some columns may be NaN or missing\n",
    "    for _, row in profanity_df.iterrows():\n",
    "        # Use pd.notna() to check that category columns are not NaN (missing values)\n",
    "        category_1 = row['category_1'] if pd.notna(row['category_1']) else ''\n",
    "        category_2 = row['category_2'] if pd.notna(row['category_2']) else ''\n",
    "        category_3 = row['category_3'] if pd.notna(row['category_3']) else ''\n",
    "\n",
    "        # If the word belongs to the sexual content category, add it to the dictionary\n",
    "        if 'sexual' in category_1 or 'sexual' in category_2 or 'sexual' in category_3:\n",
    "            sexual_content_dict.add(row['canonical_form_1'])\n",
    "            if pd.notna(row['canonical_form_2']):\n",
    "                sexual_content_dict.add(row['canonical_form_2'])\n",
    "            if pd.notna(row['canonical_form_3']):\n",
    "                sexual_content_dict.add(row['canonical_form_3'])\n",
    "\n",
    "        # If the word belongs to the racial content category, add it to the dictionary\n",
    "        if 'racial' in category_1 or 'racial' in category_2 or 'racial' in category_3:\n",
    "            racial_content_dict.add(row['canonical_form_1'])\n",
    "            if pd.notna(row['canonical_form_2']):\n",
    "                racial_content_dict.add(row['canonical_form_2'])\n",
    "            if pd.notna(row['canonical_form_3']):\n",
    "                racial_content_dict.add(row['canonical_form_3'])\n",
    "\n",
    "        # If the word belongs to the religious content category, add it to the dictionary\n",
    "        if 'religious' in category_1 or 'religious' in category_2 or 'religious' in category_3:\n",
    "            religious_content_dict.add(row['canonical_form_1'])\n",
    "            if pd.notna(row['canonical_form_2']):\n",
    "                religious_content_dict.add(row['canonical_form_2'])\n",
    "            if pd.notna(row['canonical_form_3']):\n",
    "                religious_content_dict.add(row['canonical_form_3'])\n",
    "\n",
    "    return sexual_content_dict, racial_content_dict, religious_content_dict\n",
    "\n",
    "# Build the dictionaries using the function\n",
    "sexual_content_dict, racial_content_dict, religious_content_dict = build_dictionaries(profanity_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b2c6f0-aaba-404a-b26c-4eebb072ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Use Word2Vec to extend the dictionaries with related words\n",
    "# Load the pre-trained Word2Vec model (GoogleNews vectors)\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Function to find top n synonyms for a given word using Word2Vec\n",
    "def find_synonyms_word2vec(word, model, topn=10):\n",
    "    try:\n",
    "        # Fetch the top 'n' most similar words\n",
    "        synonyms = model.most_similar(word, topn=topn)\n",
    "        return [syn for syn, score in synonyms]  # Only return the words (synonyms)\n",
    "    except KeyError:\n",
    "        return []  # If the word is not found in the model, return an empty list\n",
    "\n",
    "# Function to extend the dictionary with synonyms using Word2Vec\n",
    "def extend_dictionary_with_word2vec(dictionary, model):\n",
    "    extended_dict = set(dictionary)  # Start with the original dictionary\n",
    "    for word in dictionary:\n",
    "        synonyms = find_synonyms_word2vec(word, model)\n",
    "        extended_dict.update(synonyms)  # Add the found synonyms to the dictionary\n",
    "    return extended_dict\n",
    "\n",
    "# Step 4: Use WordNet (NLTK) to further extend the dictionaries with synonyms\n",
    "# Function to find synonyms using WordNet (lexical database)\n",
    "def find_wordnet_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())  # Add each lemma (synonym) to the set\n",
    "    return synonyms\n",
    "\n",
    "# Function to extend the dictionary with synonyms from WordNet\n",
    "def extend_dictionary_with_wordnet(dictionary):\n",
    "    extended_dict = set(dictionary)  # Start with the original dictionary\n",
    "    for word in dictionary:\n",
    "        synonyms = find_wordnet_synonyms(word)\n",
    "        extended_dict.update(synonyms)  # Add the found synonyms to the dictionary\n",
    "    return extended_dict\n",
    "\n",
    "# Now, extend each dictionary using both Word2Vec and WordNet\n",
    "# Start by extending the sexual content dictionary with Word2Vec, then WordNet\n",
    "extended_sexual_content_dict = extend_dictionary_with_word2vec(sexual_content_dict, word2vec_model)\n",
    "extended_sexual_content_dict = extend_dictionary_with_wordnet(extended_sexual_content_dict)\n",
    "\n",
    "# Do the same for the racial content dictionary\n",
    "extended_racial_content_dict = extend_dictionary_with_word2vec(racial_content_dict, word2vec_model)\n",
    "extended_racial_content_dict = extend_dictionary_with_wordnet(extended_racial_content_dict)\n",
    "\n",
    "# And finally, for the religious content dictionary\n",
    "extended_religious_content_dict = extend_dictionary_with_word2vec(religious_content_dict, word2vec_model)\n",
    "extended_religious_content_dict = extend_dictionary_with_wordnet(extended_religious_content_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099c61ea-fc27-4e21-b797-8f7896ed6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define a function to check if lyrics contain words from a specific dictionary\n",
    "def check_category(lyrics, dictionary):\n",
    "    if pd.isna(lyrics):  # If the lyrics are missing (NaN), return 0 (no matches)\n",
    "        return 0\n",
    "    # Convert the lyrics to lowercase and split into words (basic tokenization)\n",
    "    tokens = lyrics.lower().split()  \n",
    "    # Return the count of words in the lyrics that match words in the given dictionary\n",
    "    return sum(1 for word in tokens if word in dictionary)\n",
    "\n",
    "# Step 7: Add new features to the DataFrame based on the extended dictionaries\n",
    "# For each song, count how many words match the sexual content dictionary\n",
    "lyrics_df['sexual_content_count'] = lyrics_df['lyrics'].apply(lambda x: check_category(x, extended_sexual_content_dict))\n",
    "# Similarly, count the number of matches for racial content\n",
    "lyrics_df['racial_content_count'] = lyrics_df['lyrics'].apply(lambda x: check_category(x, extended_racial_content_dict))\n",
    "# And for religious content\n",
    "lyrics_df['religious_content_count'] = lyrics_df['lyrics'].apply(lambda x: check_category(x, extended_religious_content_dict))\n",
    "\n",
    "# Create binary features indicating whether the lyrics contain any words from these categories\n",
    "# If the count of sexual content words is greater than 0, mark it as 1 (True), otherwise 0 (False)\n",
    "lyrics_df['contains_sexual_content'] = lyrics_df['sexual_content_count'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# Do the same for racial content\n",
    "lyrics_df['contains_racial_content'] = lyrics_df['racial_content_count'].apply(lambda x: 1 if x > 0 else 0)\n",
    "# And for religious content\n",
    "lyrics_df['contains_religious_content'] = lyrics_df['religious_content_count'].apply(lambda x: 1 if x > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663a8c5a-efe7-4825-8443-a7015ecdeff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            artist_all          artist_base  rank                       song  \\\n",
      "0          percy faith          percy faith     1  theme from a summer place   \n",
      "1           jim reeves           jim reeves     2           he'll have to go   \n",
      "2  the everly brothers  the everly brothers     3              cathy's clown   \n",
      "3       johnny preston       johnny preston     4               running bear   \n",
      "4         mark dinning         mark dinning     5                 teen angel   \n",
      "\n",
      "   year artist_featured                 song_clean         artist_clean  \\\n",
      "0  1960             NaN  theme from a summer place          percy faith   \n",
      "1  1960             NaN            hell have to go           jim reeves   \n",
      "2  1960             NaN               cathys clown  the everly brothers   \n",
      "3  1960             NaN               running bear       johnny preston   \n",
      "4  1960             NaN                 teen angel         mark dinning   \n",
      "\n",
      "                                              lyrics  acousticness  ...  \\\n",
      "0  theres a summer place where it may rain or sto...         0.631  ...   \n",
      "1  put your sweet lips a little closer to the pho...         0.909  ...   \n",
      "2   dont want your love any more dont want your k...         0.412  ...   \n",
      "3  on the bank of the river stood running bear yo...         0.854  ...   \n",
      "4  teen angel teen angel teen angel that fateful ...         0.936  ...   \n",
      "\n",
      "   words_per_sec  num_uniq_words  decade  uniq_ratio  sexual_content_count  \\\n",
      "0       0.717771            58.0    1960    1.793103                     6   \n",
      "1       1.096365            69.0    1960    2.202899                    11   \n",
      "2       0.840202            64.0    1960    1.890625                     5   \n",
      "3       1.390645            89.0    1960    2.471910                    15   \n",
      "4       0.681706            73.0    1960    1.493151                     5   \n",
      "\n",
      "   racial_content_count  religious_content_count  contains_sexual_content  \\\n",
      "0                     3                        4                        1   \n",
      "1                     6                        7                        1   \n",
      "2                     4                        4                        1   \n",
      "3                     7                        7                        1   \n",
      "4                     4                        1                        1   \n",
      "\n",
      "   contains_racial_content contains_religious_content  \n",
      "0                        1                          1  \n",
      "1                        1                          1  \n",
      "2                        1                          1  \n",
      "3                        1                          1  \n",
      "4                        1                          1  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Save the updated DataFrame to a new CSV file\n",
    "# This file will now include the new features based on the dictionaries we built\n",
    "lyrics_df.to_csv('updated_billboard_lyrics_extended.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame to check if everything looks correct\n",
    "print(lyrics_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f5919-07da-4731-a7cf-d5ae6ea7123c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
