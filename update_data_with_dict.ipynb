{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164570dd-d5e5-41a1-a7be-04d459460ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/armanenginsucu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Ensure nltk resources are downloaded\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa0dd8a-ffbf-478e-a0b3-76b8567e9492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyrics Data:\n",
      "            artist_all          artist_base  rank                       song  \\\n",
      "0          percy faith          percy faith     1  theme from a summer place   \n",
      "1           jim reeves           jim reeves     2           he'll have to go   \n",
      "2  the everly brothers  the everly brothers     3              cathy's clown   \n",
      "3       johnny preston       johnny preston     4               running bear   \n",
      "4         mark dinning         mark dinning     5                 teen angel   \n",
      "\n",
      "   year artist_featured                 song_clean         artist_clean  \\\n",
      "0  1960             NaN  theme from a summer place          percy faith   \n",
      "1  1960             NaN            hell have to go           jim reeves   \n",
      "2  1960             NaN               cathys clown  the everly brothers   \n",
      "3  1960             NaN               running bear       johnny preston   \n",
      "4  1960             NaN                 teen angel         mark dinning   \n",
      "\n",
      "                                              lyrics  acousticness  ...  \\\n",
      "0  theres a summer place where it may rain or sto...         0.631  ...   \n",
      "1  put your sweet lips a little closer to the pho...         0.909  ...   \n",
      "2   dont want your love any more dont want your k...         0.412  ...   \n",
      "3  on the bank of the river stood running bear yo...         0.854  ...   \n",
      "4  teen angel teen angel teen angel that fateful ...         0.936  ...   \n",
      "\n",
      "   speechiness    tempo  time_signature  valence  duration_min  num_words  \\\n",
      "0       0.0253   92.631             4.0    0.749      2.414883      104.0   \n",
      "1       0.0379   81.181             3.0    0.200      2.310667      152.0   \n",
      "2       0.0339  119.809             4.0    0.866      2.400217      121.0   \n",
      "3       0.0530  119.987             4.0    0.822      2.636667      220.0   \n",
      "4       0.0459  101.517             4.0    0.282      2.664883      109.0   \n",
      "\n",
      "   words_per_sec  num_uniq_words  decade uniq_ratio  \n",
      "0       0.717771            58.0    1960   1.793103  \n",
      "1       1.096365            69.0    1960   2.202899  \n",
      "2       0.840202            64.0    1960   1.890625  \n",
      "3       1.390645            89.0    1960   2.471910  \n",
      "4       0.681706            73.0    1960   1.493151  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Profanity Data:\n",
      "        text canonical_form_1 canonical_form_2 canonical_form_3  \\\n",
      "0         69               69              NaN              NaN   \n",
      "1        @55              ass              NaN              NaN   \n",
      "2   @ssfcker             fuck              ass              NaN   \n",
      "3  @ssfucker             fuck              ass              NaN   \n",
      "4  @ssfvcker             fuck              ass              NaN   \n",
      "\n",
      "                     category_1                   category_2 category_3  \\\n",
      "0  sexual anatomy / sexual acts                          NaN        NaN   \n",
      "1  sexual anatomy / sexual acts                          NaN        NaN   \n",
      "2  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
      "3  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
      "4  sexual anatomy / sexual acts  sexual orientation / gender        NaN   \n",
      "\n",
      "   severity_rating severity_description  \n",
      "0              1.0                 Mild  \n",
      "1              1.0                 Mild  \n",
      "2              2.8               Severe  \n",
      "3              2.8               Severe  \n",
      "4              2.4               Strong  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load your data files\n",
    "lyrics_df = pd.read_csv('billboard-lyrics-spotify.csv')\n",
    "profanity_df = pd.read_csv('profanity_en.csv')\n",
    "\n",
    "# Display the first few rows of both datasets\n",
    "print(\"Lyrics Data:\")\n",
    "print(lyrics_df.head())\n",
    "\n",
    "print(\"\\nProfanity Data:\")\n",
    "print(profanity_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c055e8c-2cf4-41b2-b467-024fefdcd8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the dictionaries from 'profanity_en.csv'\n",
    "def build_dictionaries(profanity_df):\n",
    "    sexual_content_dict = set()\n",
    "    racial_content_dict = set()\n",
    "    religious_content_dict = set()\n",
    "\n",
    "    # Safely handle cases where some columns might be NaN or missing\n",
    "    for _, row in profanity_df.iterrows():\n",
    "        # Use pd.notna() to ensure the category columns are not NaN\n",
    "        category_1 = row['category_1'] if pd.notna(row['category_1']) else ''\n",
    "        category_2 = row['category_2'] if pd.notna(row['category_2']) else ''\n",
    "        category_3 = row['category_3'] if pd.notna(row['category_3']) else ''\n",
    "\n",
    "        # Check if the word belongs to sexual content category\n",
    "        if 'sexual' in category_1 or 'sexual' in category_2 or 'sexual' in category_3:\n",
    "            sexual_content_dict.add(row['canonical_form_1'])\n",
    "            if pd.notna(row['canonical_form_2']):\n",
    "                sexual_content_dict.add(row['canonical_form_2'])\n",
    "            if pd.notna(row['canonical_form_3']):\n",
    "                sexual_content_dict.add(row['canonical_form_3'])\n",
    "\n",
    "        # Check if the word belongs to racial content category\n",
    "        if 'racial' in category_1 or 'racial' in category_2 or 'racial' in category_3:\n",
    "            racial_content_dict.add(row['canonical_form_1'])\n",
    "            if pd.notna(row['canonical_form_2']):\n",
    "                racial_content_dict.add(row['canonical_form_2'])\n",
    "            if pd.notna(row['canonical_form_3']):\n",
    "                racial_content_dict.add(row['canonical_form_3'])\n",
    "\n",
    "        # Check if the word belongs to religious content category\n",
    "        if 'religious' in category_1 or 'religious' in category_2 or 'religious' in category_3:\n",
    "            religious_content_dict.add(row['canonical_form_1'])\n",
    "            if pd.notna(row['canonical_form_2']):\n",
    "                religious_content_dict.add(row['canonical_form_2'])\n",
    "            if pd.notna(row['canonical_form_3']):\n",
    "                religious_content_dict.add(row['canonical_form_3'])\n",
    "\n",
    "    return sexual_content_dict, racial_content_dict, religious_content_dict\n",
    "\n",
    "# Build the dictionaries\n",
    "sexual_content_dict, racial_content_dict, religious_content_dict = build_dictionaries(profanity_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b2c6f0-aaba-404a-b26c-4eebb072ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extend dictionaries using Word2Vec (Pre-trained Model)\n",
    "# Load pre-trained Word2Vec model\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "def find_synonyms_word2vec(word, model, topn=10):\n",
    "    try:\n",
    "        synonyms = model.most_similar(word, topn=topn)\n",
    "        return [syn for syn, score in synonyms]\n",
    "    except KeyError:\n",
    "        return []\n",
    "\n",
    "def extend_dictionary_with_word2vec(dictionary, model):\n",
    "    extended_dict = set(dictionary)\n",
    "    for word in dictionary:\n",
    "        synonyms = find_synonyms_word2vec(word, model)\n",
    "        extended_dict.update(synonyms)\n",
    "    return extended_dict\n",
    "\n",
    "# Step 4: Extend dictionaries using WordNet (NLTK)\n",
    "def find_wordnet_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())  # Add lemma (synonym)\n",
    "    return synonyms\n",
    "\n",
    "def extend_dictionary_with_wordnet(dictionary):\n",
    "    extended_dict = set(dictionary)\n",
    "    for word in dictionary:\n",
    "        synonyms = find_wordnet_synonyms(word)\n",
    "        extended_dict.update(synonyms)\n",
    "    return extended_dict\n",
    "\n",
    "# Extend each dictionary with both Word2Vec and WordNet\n",
    "extended_sexual_content_dict = extend_dictionary_with_word2vec(sexual_content_dict, word2vec_model)\n",
    "extended_sexual_content_dict = extend_dictionary_with_wordnet(extended_sexual_content_dict)\n",
    "\n",
    "extended_racial_content_dict = extend_dictionary_with_word2vec(racial_content_dict, word2vec_model)\n",
    "extended_racial_content_dict = extend_dictionary_with_wordnet(extended_racial_content_dict)\n",
    "\n",
    "extended_religious_content_dict = extend_dictionary_with_word2vec(religious_content_dict, word2vec_model)\n",
    "extended_religious_content_dict = extend_dictionary_with_wordnet(extended_religious_content_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099c61ea-fc27-4e21-b797-8f7896ed6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Define a function to check lyrics against the extended dictionaries\n",
    "def check_category(lyrics, dictionary):\n",
    "    if pd.isna(lyrics):  # Handle NaN values\n",
    "        return 0\n",
    "    tokens = lyrics.lower().split()  # Simple tokenization by splitting words\n",
    "    return sum(1 for word in tokens if word in dictionary)\n",
    "\n",
    "# Step 7: Add new features to the lyrics DataFrame based on the extended dictionaries\n",
    "lyrics_df['sexual_content_count'] = lyrics_df['lyrics'].apply(lambda x: check_category(x, extended_sexual_content_dict))\n",
    "lyrics_df['racial_content_count'] = lyrics_df['lyrics'].apply(lambda x: check_category(x, extended_racial_content_dict))\n",
    "lyrics_df['religious_content_count'] = lyrics_df['lyrics'].apply(lambda x: check_category(x, extended_religious_content_dict))\n",
    "\n",
    "# Add binary features for presence of content\n",
    "lyrics_df['contains_sexual_content'] = lyrics_df['sexual_content_count'].apply(lambda x: 1 if x > 0 else 0)\n",
    "lyrics_df['contains_racial_content'] = lyrics_df['racial_content_count'].apply(lambda x: 1 if x > 0 else 0)\n",
    "lyrics_df['contains_religious_content'] = lyrics_df['religious_content_count'].apply(lambda x: 1 if x > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663a8c5a-efe7-4825-8443-a7015ecdeff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            artist_all          artist_base  rank                       song  \\\n",
      "0          percy faith          percy faith     1  theme from a summer place   \n",
      "1           jim reeves           jim reeves     2           he'll have to go   \n",
      "2  the everly brothers  the everly brothers     3              cathy's clown   \n",
      "3       johnny preston       johnny preston     4               running bear   \n",
      "4         mark dinning         mark dinning     5                 teen angel   \n",
      "\n",
      "   year artist_featured                 song_clean         artist_clean  \\\n",
      "0  1960             NaN  theme from a summer place          percy faith   \n",
      "1  1960             NaN            hell have to go           jim reeves   \n",
      "2  1960             NaN               cathys clown  the everly brothers   \n",
      "3  1960             NaN               running bear       johnny preston   \n",
      "4  1960             NaN                 teen angel         mark dinning   \n",
      "\n",
      "                                              lyrics  acousticness  ...  \\\n",
      "0  theres a summer place where it may rain or sto...         0.631  ...   \n",
      "1  put your sweet lips a little closer to the pho...         0.909  ...   \n",
      "2   dont want your love any more dont want your k...         0.412  ...   \n",
      "3  on the bank of the river stood running bear yo...         0.854  ...   \n",
      "4  teen angel teen angel teen angel that fateful ...         0.936  ...   \n",
      "\n",
      "   words_per_sec  num_uniq_words  decade  uniq_ratio  sexual_content_count  \\\n",
      "0       0.717771            58.0    1960    1.793103                     6   \n",
      "1       1.096365            69.0    1960    2.202899                    11   \n",
      "2       0.840202            64.0    1960    1.890625                     5   \n",
      "3       1.390645            89.0    1960    2.471910                    15   \n",
      "4       0.681706            73.0    1960    1.493151                     5   \n",
      "\n",
      "   racial_content_count  religious_content_count  contains_sexual_content  \\\n",
      "0                     3                        4                        1   \n",
      "1                     6                        7                        1   \n",
      "2                     4                        4                        1   \n",
      "3                     7                        7                        1   \n",
      "4                     4                        1                        1   \n",
      "\n",
      "   contains_racial_content contains_religious_content  \n",
      "0                        1                          1  \n",
      "1                        1                          1  \n",
      "2                        1                          1  \n",
      "3                        1                          1  \n",
      "4                        1                          1  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Save the updated dataset with the extended dictionaries applied\n",
    "lyrics_df.to_csv('updated_billboard_lyrics_extended.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the updated dataset\n",
    "print(lyrics_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f5919-07da-4731-a7cf-d5ae6ea7123c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
